<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Apprentissage automatique interprétable</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../09-local_model_agnostic_methods/09.6-shap.html" rel="next">
<link href="../09-local_model_agnostic_methods/09.4-anchors.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer",
    "search-label": "Recherche"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../09-local_model_agnostic_methods/index.html">9 - Méthodes locales indépendantes du modèle</a></li><li class="breadcrumb-item"><a href="../09-local_model_agnostic_methods/09.5-shapley.html">9.5 - Valeurs de Shapley</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Apprentissage automatique interprétable</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../00-summary/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Résumé</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../01-preface/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - Préface de l’auteur</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../02-introduction/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.1-short_stories.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.1 - Quelques histoires</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.2-ml_definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.2 - Qu’est-ce que l’apprentissage automatique ?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.3-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.3 - Terminologie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../03-interpretability/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - Interprétabilité</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.1-importance_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1 - Importance de l’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.2-taxonomy_of_interpretability_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.2 - Taxonomie des Méthodes d’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.3-scope_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.3 - Portée de l’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.4-evaluation_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.4 - Evaluation de l’interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.5-properties_of_explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.5 - Propriétés des Explications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.6-human_friendly_explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.6 - Explications conviviales pour l’être humain</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../04-datasets/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - Jeux de données</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.1-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.1 - Location de vélo (Régression)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.2-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.2 - Commentaires indésirables sur YouTube (Classification de Texte)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.3-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.3 - Facteurs de Risque du Cancer du Col de l’Uterus (Classification)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../05-interpretable_models/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - Modèles interprétables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.1-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.1 - Régéression linéaire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.2-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.2 - Régéression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.3-glm-gam-more.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.3 - GLM, GAM et plus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.4-decision-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.4 - Arbre de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.5-decision-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.5 - Règles de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.6-rulefit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.6 - Ajustement des règles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.7-other-interpretable-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.7 - Autres modèles interprétables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../06-model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 - Méthodes indépendantes du modèle</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../07-example/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 - Explications basées sur des exemples</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../08-global_model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 - Méthodes globales indépendantes du modèle</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.1-pdp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.1 - Diagramme de dépendance partielle (PDP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.2-ale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.2 - Graphique des effets locaux accumulés (ALE)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.3-feature-interaction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.3 - Interactions avec les fonctionnalités</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.4-functional-decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.4 - Functional Decomposition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.5-permutation-feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.5 - Décomposition fonctionnelle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.6-global-surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.6 - Substitut global</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.7-prototype-criticisms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.7 - Prototypes et critiques</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../09-local_model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 - Méthodes locales indépendantes du modèle</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.1-ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.1 - Attente Conditionnelle Individuelle (<em>Individual Conditional Expectation - ICE</em>)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.2-lime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.2 - Substitut local (LIME)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.3-counterfactual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.3 - Explications contrefactuelles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.4-anchors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.4 - Règles de portée (ancres)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.5-shapley.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">9.5 - Valeurs de Shapley</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.6-shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.6 - SHAP (SHapley Additive exPlanations)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../10-neuralnet/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10 - Interprétation d'un réseau de neurone</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.1-learned-features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.1 - Caractéristiques apprises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.2-pixel-attribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.2 - Attribution de pixel</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.3-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.3 - Détecter les concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.4-adversarial-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.4 - Exemples adverses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.5-influential-instances.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.5 - Instances Influentes</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../11-future/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 - Un Regard dans une boule de cristal</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../11-future/11.1-future-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11.1 - L’avenir de l’apprentissage automatique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../11-future/11.2-future-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11.2 - L’avenir de l’interprétabilité</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../12-contribute/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 - Contribuer à ce livre</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../13-citation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 - Citer ce livre</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../14-translations/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14 - Traductions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../15-acknowledgements/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15 - Remerciements</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="4">
    <h2 id="toc-title">Dans cette page</h2>
   
  <ul>
  <li><a href="#valeurs-de-shapley" id="toc-valeurs-de-shapley" class="nav-link active" data-scroll-target="#valeurs-de-shapley">9.5 - Valeurs de Shapley</a>
  <ul>
  <li><a href="#idée-générale" id="toc-idée-générale" class="nav-link" data-scroll-target="#idée-générale">9.5.1 - Idée générale</a></li>
  <li><a href="#exemples-et-interprétation" id="toc-exemples-et-interprétation" class="nav-link" data-scroll-target="#exemples-et-interprétation">9.5.2 - Exemples et interprétation</a></li>
  <li><a href="#la-valeur-shapley-en-détail" id="toc-la-valeur-shapley-en-détail" class="nav-link" data-scroll-target="#la-valeur-shapley-en-détail">9.5.3 - La valeur Shapley en détail</a>
  <ul class="collapse">
  <li><a href="#la-valeur-shapley" id="toc-la-valeur-shapley" class="nav-link" data-scroll-target="#la-valeur-shapley">9.5.3.1 - La valeur Shapley</a></li>
  <li><a href="#intuitions" id="toc-intuitions" class="nav-link" data-scroll-target="#intuitions">9.5.3.2 - Intuitions</a></li>
  <li><a href="#estimation-de-la-valeur-de-shapley" id="toc-estimation-de-la-valeur-de-shapley" class="nav-link" data-scroll-target="#estimation-de-la-valeur-de-shapley">9.5.3.3 - Estimation de la valeur de Shapley</a></li>
  </ul></li>
  <li><a href="#avantages" id="toc-avantages" class="nav-link" data-scroll-target="#avantages">9.5.4 - Avantages</a></li>
  <li><a href="#inconvénients" id="toc-inconvénients" class="nav-link" data-scroll-target="#inconvénients">9.5.5 - Inconvénients</a></li>
  <li><a href="#logiciels-et-alternatives" id="toc-logiciels-et-alternatives" class="nav-link" data-scroll-target="#logiciels-et-alternatives">9.5.6 - Logiciels et alternatives</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../09-local_model_agnostic_methods/index.html">9 - Méthodes locales indépendantes du modèle</a></li><li class="breadcrumb-item"><a href="../09-local_model_agnostic_methods/09.5-shapley.html">9.5 - Valeurs de Shapley</a></li></ol></nav>
<div class="quarto-title">
</div>



<div class="quarto-title-meta">

    
  
    <div>
    <div class="quarto-title-meta-heading">Modifié</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">10 mai 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="valeurs-de-shapley" class="level2">
<h2 class="anchored" data-anchor-id="valeurs-de-shapley">9.5 - Valeurs de Shapley</h2>
<p>Une prédiction peut être expliquée en supposant que chaque valeur de caractéristique de l’instance est un « joueur » dans un jeu où la prédiction est le paiement. Les valeurs de Shapley – une méthode issue de la théorie des jeux coalitionnels – nous indiquent comment répartir équitablement le « paiement » entre les fonctionnalités.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Vous recherchez un livre pratique et approfondi sur les valeurs SHAP et Shapley ? <a href="https://leanpub.com/shap">J’en ai trouvé un pour vous</a>.</p>
</div>
</div>
<section id="idée-générale" class="level3">
<h3 class="anchored" data-anchor-id="idée-générale">9.5.1 - Idée générale</h3>
<p>Supposons le scénario suivant :</p>
<p>Vous avez entraîné un modèle d’apprentissage automatique pour prédire les prix des appartements. Pour un certain appartement, il prévoit 300 000 € et vous devez expliquer cette prévision. L’appartement a une superficie de 50 m 2 , est situé au 2ème étage, dispose d’un parc à proximité et les chats sont interdits :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images/shapley-instance.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Le prix prévu pour un appartement de $50 m<span class="math inline">\(2\)</span> au 2ème étage avec un parc à proximité et une interdiction de chat est de 300 000 €. Notre objectif est d’expliquer comment chacune de ces valeurs de caractéristiques a contribué à la prédiction.</figcaption>
</figure>
</div>
<p>La prévision moyenne pour tous les appartements est de 310 000 €. Dans quelle mesure chaque valeur de caractéristique a-t-elle contribué à la prédiction par rapport à la prédiction moyenne ?</p>
<p>La réponse est simple pour les modèles de régression linéaire. L’effet de chaque fonctionnalité est le poids de la fonctionnalité multiplié par la valeur de la fonctionnalité. Cela ne fonctionne qu’en raison de la linéarité du modèle. Pour les modèles plus complexes, nous avons besoin d’une solution différente. Par exemple, <a href="../09-local_model_agnostic_methods/09.2-lime.html">LIME</a> propose des modèles locaux pour estimer les effets. Une autre solution vient de la théorie des jeux coopératifs : la valeur de Shapley, inventée par Shapley (1953)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, est une méthode permettant d’attribuer des paiements aux joueurs en fonction de leur contribution au paiement total. Les joueurs coopèrent au sein d’une coalition et tirent un certain profit de cette coopération.</p>
<p>Joueurs? Jeu? Paiement ? Quel est le lien avec les prédictions et l’interprétabilité de l’apprentissage automatique ? Le « jeu » est la tâche de prédiction pour une seule instance de l’ensemble de données. Le « gain » est la prédiction réelle pour cette instance moins la prédiction moyenne pour toutes les instances. Les « joueurs » sont les valeurs des caractéristiques de l’instance qui collaborent pour recevoir le gain (= prédire une certaine valeur). Dans notre exemple d’appartement, les valeurs de caractéristique <code>park-nearby</code>, <code>cat-banned</code> et <code>area-50</code> ont <code>floor-2nd</code> travaillé ensemble pour atteindre la prédiction de 300 000 €. Notre objectif est d’expliquer l’écart entre la prédiction réelle (300 000 €) et la prédiction moyenne (310 000 €) : un écart de -10 000 €.</p>
<p>La réponse pourrait être : les <code>park-nearby</code> 30 000 € cotisés ; <code>area-50</code> contribué 10 000 € ; <code>floor-2nd</code> cotisé 0 € ; <code>cat-banned</code> apporté -50 000 €. Les cotisations s’élèvent à -10 000 €, la prévision finale moins le prix moyen prévisionnel de l’appartement.</p>
<p><strong>Comment calculons-nous la valeur de Shapley pour une caractéristique ?</strong></p>
<p>La valeur de Shapley est la contribution marginale moyenne d’une valeur de caractéristique dans toutes les coalitions possibles. Tout est clair maintenant ?</p>
<p>Dans la figure suivante, nous évaluons la contribution de la <code>cat-banned</code> valeur de la caractéristique lorsqu’elle est ajoutée à une coalition de <code>park-nearby</code> et <code>area-50</code>. Nous simulons cela uniquement <code>park-nearby</code>, <code>cat-banned</code> et <code>area-50</code> sont une coalition en tirant au hasard un autre appartement à partir des données et en utilisant sa valeur pour la caractéristique d’étage La valeur <code>floor-2nd</code> a été remplacée par celle tirée au hasard floor-1st. On prédit ensuite le prix de l’appartement avec cette combinaison (310 000 €). Dans un deuxième temps, nous retirons cat-bannedde la coalition en la remplaçant par une valeur aléatoire de la caractéristique chat autorisé/banni de l’appartement tiré au sort. Dans l’exemple, c’était <code>cat-allowed</code>, mais cela aurait pu être <code>cat-banned</code> à nouveau. Nous prévoyons le prix de l’appartement pour la coalition des <code>park-nearby</code> et <code>area-50</code> (320 000 €). La contribution de <code>cat-banned</code> était de 310 000 € - 320 000 € = -10 000 €. Cette estimation dépend des valeurs de l’appartement tiré au hasard qui a servi de « donneur » pour les valeurs des caractéristiques du chat et de l’étage. Nous obtiendrons de meilleures estimations si nous répétons cette étape d’échantillonnage et faisons la moyenne des contributions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images/shapley-instance-intervention.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Un échantillon de répétition pour estimer la contribution de cat-bannedà la prédiction lorsqu’il est ajouté à la coalition de <code>park-nearby</code> et <code>area-50</code>.</figcaption>
</figure>
</div>
<p>Nous répétons ce calcul pour toutes les coalitions possibles. La valeur de Shapley est la moyenne de toutes les contributions marginales à toutes les coalitions possibles. Le temps de calcul augmente de façon exponentielle avec le nombre de fonctionnalités. Une solution pour conserver un temps de calcul gérable consiste à calculer les contributions pour seulement quelques échantillons des coalitions possibles.</p>
<p>La figure suivante montre toutes les coalitions de valeurs de caractéristiques nécessaires pour déterminer la valeur de Shapley pour <code>cat-banned</code>. La première ligne montre la coalition sans aucune valeur de caractéristique. Les deuxième, troisième et quatrième lignes montrent différentes coalitions avec une taille croissante, séparées par « | ». Au total, les coalitions suivantes sont possibles :</p>
<ul>
<li><code>No feature values</code></li>
<li><code>park-nearby</code></li>
<li><code>area-50</code></li>
<li><code>floor-2nd</code></li>
<li><code>park-nearby</code> + <code>area-50</code></li>
<li><code>park-nearby</code> + <code>floor-2nd</code></li>
<li><code>area-50</code> + <code>floor-2nd</code></li>
<li><code>park-nearby</code> + <code>area-50</code> + <code>floor-2nd</code></li>
</ul>
<p>Pour chacune de ces coalitions, nous calculons le prix prévu de l’appartement avec et sans la valeur caractéristique <code>cat-banned</code> et prenons la différence pour obtenir la contribution marginale. La valeur Shapley est la moyenne (pondérée) des contributions marginales. Nous remplaçons les valeurs des caractéristiques qui ne font pas partie d’une coalition par des valeurs de caractéristiques aléatoires de l’ensemble de données d’appartement pour obtenir une prédiction du modèle d’apprentissage automatique.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images/shapley-coalitions.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Les 8 coalitions nécessaires pour calculer la valeur Shapley exacte de la <code>cat-banned</code> valeur de la caractéristique.</figcaption>
</figure>
</div>
<p>Si nous estimons les valeurs de Shapley pour toutes les valeurs de caractéristiques, nous obtenons la distribution complète de la prédiction (moins la moyenne) parmi les valeurs de caractéristiques.</p>
</section>
<section id="exemples-et-interprétation" class="level3">
<h3 class="anchored" data-anchor-id="exemples-et-interprétation">9.5.2 - Exemples et interprétation</h3>
<p>L’interprétation de la valeur de Shapley pour la valeur de caractéristique <span class="math inline">\(j\)</span> est la suivante : la valeur de la <span class="math inline">\(j^{ième}\)</span> caractéristique apportée <span class="math inline">\(\phi_j\)</span> à la prédiction de cette instance particulière par rapport à la prédiction moyenne pour l’ensemble de données.</p>
<p>La valeur de Shapley fonctionne à la fois pour la classification (si nous avons affaire à des probabilités) et pour la régression.</p>
<p>Nous utilisons la valeur de Shapley pour analyser les prédictions d’un modèle forestier aléatoire prédisant <a href="../04-datasets/04.3-datasets.html">le cancer du col de l’utérus</a> :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/9_5_2_fig_1.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Valeurs Shapley pour une femme dans l’ensemble de données sur le cancer du col de l’utérus. Avec une prédiction de 0,57, la probabilité de cancer de cette femme est de 0,54 supérieure à la prédiction moyenne de 0,03. Le nombre de MST diagnostiquées augmente le plus la probabilité. La somme des contributions donne la différence entre la prévision réelle et moyenne (0,54).</figcaption>
</figure>
</div>
<p>Pour l’<a href="../04-datasets/04.1-datasets.html">ensemble de données de location de vélos</a>, nous formons également une forêt aléatoire pour prédire le nombre de vélos loués pour une journée, en fonction des informations météorologiques et du calendrier. Les explications créées pour la prédiction aléatoire de la forêt d’un jour particulier :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/9_5_2_fig_2.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Valeurs Shapley pour le jour 285. Avec une prévision de 2409 vélos de location, ce jour est de -2108 en dessous de la prévision moyenne de 4518. La situation météorologique et l’humidité ont eu les contributions négatives les plus importantes. La température de cette journée a eu une contribution positive. La somme des valeurs de Shapley donne la différence entre les prévisions réelles et moyennes (-2 108).</figcaption>
</figure>
</div>
<p>Attention à interpréter correctement la valeur de Shapley : la valeur de Shapley est la contribution moyenne d’une valeur de caractéristique à la prédiction dans différentes coalitions. La valeur de Shapley n’est PAS la différence de prédiction lorsque nous supprimerions la fonctionnalité du modèle.</p>
</section>
<section id="la-valeur-shapley-en-détail" class="level3">
<h3 class="anchored" data-anchor-id="la-valeur-shapley-en-détail">9.5.3 - La valeur Shapley en détail</h3>
<p>Cette section approfondit la définition et le calcul de la valeur de Shapley pour le lecteur curieux. Sautez cette section et allez directement à « Avantages et inconvénients » si les détails techniques ne vous intéressent pas.</p>
<p>Nous nous intéressons à la manière dont chaque fonctionnalité affecte la prédiction d’un point de données. Dans un modèle linéaire, il est facile de calculer les effets individuels. Voici à quoi ressemble une prédiction de modèle linéaire pour une instance de données :</p>
<p><span class="math display">\[\hat{f}(x)=\beta_0+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}\]</span></p>
<p>où <span class="math inline">\(x\)</span> est l’instance pour laquelle nous voulons calculer les contributions. Chaque <span class="math inline">\(x_j\)</span> est une valeur de caractéristique, avec <span class="math inline">\(j = 1, \dots, p\)</span>. Le <span class="math inline">\(\beta_j\)</span> est le poids correspondant à la caractéristique <span class="math inline">\(j\)</span>.</p>
<p>La contribution <span class="math inline">\(\phi_j\)</span> de la <span class="math inline">\(j^{ème}\)</span> fonctionnalité sur la prédiction <span class="math inline">\(\hat{f}(x)\)</span> est:</p>
<p><span class="math display">\[\phi_j(\hat{f})=\beta_{j}x_j-E(\beta_{j}X_{j})=\beta_{j}x_j-\beta_{j}E(X_{j})\]</span></p>
<p>où <span class="math inline">\(E(\beta_jX_{j})\)</span> est l’estimation de l’effet moyen pour la caractéristique j. La contribution est la différence entre l’effet caractéristique moins l’effet moyen. Bon! Nous savons désormais dans quelle mesure chaque fonctionnalité a contribué à la prédiction. Si nous additionnons toutes les contributions aux fonctionnalités pour une instance, le résultat est le suivant :</p>
<p><span class="math inline">\(\begin{align*}\sum_{j=1}^{p}\phi_j(\hat{f})=&amp;\sum_{j=1}^p(\beta_{j}x_j-E(\beta_{j}X_{j}))\\=&amp;(\beta_0+\sum_{j=1}^p\beta_{j}x_j)-(\beta_0+\sum_{j=1}^{p}E(\beta_{j}X_{j}))\\=&amp;\hat{f}(x)-E(\hat{f}(X))\end{align*}\)</span></p>
<p>Il s’agit de la valeur prédite pour le point de données <span class="math inline">\(x\)</span> moins la valeur prédite moyenne. Les contributions aux fonctionnalités peuvent être négatives.</p>
<p>Pouvons-nous faire la même chose pour n’importe quel type de modèle ? Ce serait formidable d’avoir cela comme un outil indépendant du modèle. Étant donné que nous n’avons généralement pas de poids similaires dans d’autres types de modèles, nous avons besoin d’une solution différente.</p>
<p>L’aide vient d’endroits inattendus : la théorie des jeux coopératifs. La valeur Shapley est une solution permettant de calculer les contributions de fonctionnalités pour des prédictions uniques pour n’importe quel modèle d’apprentissage automatique.</p>
<section id="la-valeur-shapley" class="level4">
<h4 class="anchored" data-anchor-id="la-valeur-shapley">9.5.3.1 - La valeur Shapley</h4>
<p>La valeur Shapley est définie via une fonction de valeur <span class="math inline">\(val\)</span> des joueurs en <span class="math inline">\(S\)</span>.</p>
<p>La valeur Shapley d’une valeur de caractéristique est sa contribution au paiement, pondérée et additionnée sur toutes les combinaisons possibles de valeurs de caractéristique :</p>
<p><span class="math display">\[\phi_j(val)=\sum_{S\subseteq\{1,\ldots,p\} \backslash \{j\}}\frac{|S|!\left(p-|S|-1\right)!}{p!}\left(val\left(S\cup\{j\}\right)-val(S)\right)\]</span></p>
<p>où <span class="math inline">\(S\)</span> est un sous-ensemble des fonctionnalités utilisées dans le modèle, <span class="math inline">\(x\)</span> est le vecteur des valeurs des fonctionnalités de l’instance à expliquer et <span class="math inline">\(p\)</span> le nombre de fonctionnalités. <span class="math inline">\(val_x(S)\)</span> est la prédiction des valeurs de caractéristiques de l’ensemble <span class="math inline">\(S\)</span> qui sont marginalisées par rapport aux caractéristiques qui ne sont pas incluses dans l’ensemble <span class="math inline">\(S\)</span> :</p>
<p><span class="math display">\[val_{x}(S)=\int\hat{f}(x_{1},\ldots,x_{p})d\mathbb{P}_{x\notin{}S}-E_X(\hat{f}(X))\]</span></p>
<p>Vous effectuez en fait plusieurs intégrations pour chaque fonctionnalité qui n’est pas contenue <span class="math inline">\(S\)</span>. Un exemple concret : Le modèle d’apprentissage automatique fonctionne avec 4 fonctionnalités <span class="math inline">\(x1\)</span>, <span class="math inline">\(x2\)</span>, <span class="math inline">\(x3\)</span> et <span class="math inline">\(x4\)</span> et nous évaluons la prédiction pour la coalition <span class="math inline">\(S\)</span> composée des valeurs de fonctionnalités <span class="math inline">\(x1\)</span> et <span class="math inline">\(x3\)</span> :</p>
<p><span class="math display">\[val_{x}(S)=val_{x}(\{1,3\})=\int_{\mathbb{R}}\int_{\mathbb{R}}\hat{f}(x_{1},X_{2},x_{3},X_{4})d\mathbb{P}_{X_2X_4}-E_X(\hat{f}(X))\]</span></p>
<p>Cela ressemble aux contributions de fonctionnalités dans le modèle linéaire !</p>
<p>Ne vous laissez pas tromper par les nombreuses utilisations du mot « valeur » : la valeur de caractéristique est la valeur numérique ou catégorielle d’une caractéristique et d’une instance ; la valeur de Shapley est la contribution des caractéristiques à la prédiction ; la fonction de valeur est la fonction de paiement pour les coalitions de joueurs (valeurs de caractéristiques).</p>
<p>La valeur Shapley est la seule méthode d’attribution qui satisfait aux propriétés <strong>Efficacité</strong>, <strong>Symétrie</strong>, <strong>Factice</strong> et <strong>Additivité</strong>, qui, ensemble, peuvent être considérées comme une définition d’un paiement équitable.</p>
<p><strong>Efficacité</strong> : Les contributions des fonctionnalités doivent correspondre à la différence de prédiction pour x et à la moyenne.</p>
<p><span class="math display">\[\sum\nolimits_{j=1}^p\phi_j=\hat{f}(x)-E_X(\hat{f}(X))\]</span></p>
<p><strong>Symétrie</strong> : Les contributions de deux valeurs de caractéristiques j et k devraient être les mêmes si elles contribuent également à toutes les coalitions possibles. Si</p>
<p><span class="math display">\[val(S \cup \{j\})=val(S\cup\{k\})\]</span></p>
<p>pour tout</p>
<p><span class="math display">\[S\subseteq\{1,\ldots, p\} \backslash \{j,k\}\]</span></p>
<p>alors</p>
<p><span class="math display">\[\phi_j = \phi_{k}\]</span></p>
<p><strong>Factice</strong> : Une caractéristique j qui ne modifie pas la valeur prédite – quelle que soit la coalition de valeurs de caractéristiques à laquelle elle est ajoutée – devrait avoir une valeur Shapley de 0. Si</p>
<p><span class="math display">\[val(S\cup\{j\})=val(S)\]</span></p>
<p>pour tout</p>
<p><span class="math display">\[S\subseteq\{1,\ldots,p\}\]</span></p>
<p>alors</p>
<p><span class="math display">\[\phi_j=0\]</span></p>
<p><strong>Additivité</strong> : Pour un jeu avec des gains combinés val+val + les valeurs Shapley respectives sont les suivantes :</p>
<p><span class="math display">\[\phi_j + \phi_j^{+}\]</span></p>
<p>Supposons que vous ayez entraîné une forêt aléatoire, ce qui signifie que la prédiction est une moyenne de plusieurs arbres de décision. La propriété Additivité garantit que pour une valeur de caractéristique, vous pouvez calculer la valeur Shapley pour chaque arbre individuellement, faire la moyenne et obtenir la valeur Shapley pour la valeur de caractéristique de la forêt aléatoire.</p>
</section>
<section id="intuitions" class="level4">
<h4 class="anchored" data-anchor-id="intuitions">9.5.3.2 - Intuitions</h4>
<p>Une manière intuitive de comprendre la valeur de Shapley est l’illustration suivante : Les valeurs de caractéristique entrent dans une pièce dans un ordre aléatoire. Toutes les valeurs caractéristiques de la salle participent au jeu (= contribuent à la prédiction). La valeur Shapley d’une valeur de caractéristique est le changement moyen de la prédiction que la coalition déjà présente dans la salle reçoit lorsque la valeur de caractéristique la rejoint.</p>
</section>
<section id="estimation-de-la-valeur-de-shapley" class="level4">
<h4 class="anchored" data-anchor-id="estimation-de-la-valeur-de-shapley">9.5.3.3 - Estimation de la valeur de Shapley</h4>
<p>Toutes les coalitions (ensembles) possibles de valeurs de caractéristiques doivent être évaluées avec et sans la j-ième caractéristique pour calculer la valeur exacte de Shapley. Pour plusieurs fonctionnalités, la solution exacte à ce problème devient problématique à mesure que le nombre de coalitions possibles augmente de façon exponentielle à mesure que davantage de fonctionnalités sont ajoutées. Strumbelj et coll. (2014)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> proposent une approximation avec échantillonnage de Monte-Carlo :</p>
<p><span class="math display">\[\hat{\phi}_{j}=\frac{1}{M}\sum_{m=1}^M\left(\hat{f}(x^{m}_{+j})-\hat{f}(x^{m}_{-j})\right)\]</span></p>
<p>où <span class="math inline">\(\hat{f}(x^{m}_{+j})\)</span> est la prédiction pour <span class="math inline">\(x\)</span>, mais avec un nombre aléatoire de valeurs de caractéristiques remplacées par des valeurs de caractéristiques provenant d’un point de données aléatoire <span class="math inline">\(z\)</span>, à l’exception de la valeur respective de la caractéristique <span class="math inline">\(j\)</span>. Le vecteur <span class="math inline">\(x^{m}_{-j}\)</span> est presque identique à <span class="math inline">\(x^{m}_{+j}\)</span>, mais la valeur <span class="math inline">\(x_j^{m}\)</span> est également tiré du <span class="math inline">\(z\)</span> échantillonné. Chacune de ces nouvelles instances <span class="math inline">\(M\)</span> est une sorte de « Monstre de Frankenstein » assemblé à partir de deux instances. Notez que dans l’algorithme suivant, l’ordre des entités n’est pas réellement modifié : chaque entité reste à la même position vectorielle lorsqu’elle est transmise à la fonction de prédiction. L’ordre n’est utilisé ici que comme « astuce » : en donnant un nouvel ordre aux fonctionnalités, nous obtenons un mécanisme aléatoire qui nous aide à composer le « Monstre de Frankenstein ». Pour les fonctionnalités qui apparaissent à gauche de la fonctionnalité <span class="math inline">\(x_j\)</span>, nous prenons les valeurs des observations originales, et pour les caractéristiques de droite, nous prenons les valeurs d’une instance aléatoire.</p>
<p><strong>Estimation Shapley approximative pour une valeur de caractéristique unique</strong> : - Sortie : valeur Shapley pour la valeur de la <span class="math inline">\(j^{ème}\)</span> fonctionnalité - Obligatoire : nombre d’itérations <span class="math inline">\(M\)</span>, instance d’intérêt <span class="math inline">\(x\)</span>, index de fonctionnalités <span class="math inline">\(j\)</span>, matrice de données <span class="math inline">\(X\)</span> et modèle d’apprentissage automatique <span class="math inline">\(f\)</span> - Pour tout <span class="math inline">\(m = 1, \dots, M\)</span> : - Dessinez une instance aléatoire <span class="math inline">\(z\)</span> à partir de la matrice de données <span class="math inline">\(X\)</span> - Choisissez une permutation aléatoire des valeurs des caractéristiques - Instance de commande <span class="math inline">\(x\)</span> : <span class="math inline">\(x_o=(x_{(1)},\ldots,x_{(j)},\ldots,x_{(p)})\)</span> - Instance de commande <span class="math inline">\(z\)</span> : <span class="math inline">\(z_o=(z_{(1)},\ldots,z_{(j)},\ldots,z_{(p)})\)</span> - Construire deux nouvelles instances - Avec <span class="math inline">\(j\)</span> : <span class="math inline">\(x_{+j}=(x_{(1)},\ldots,x_{(j-1)},x_{(j)},z_{(j+1)},\ldots,z_{(p)})\)</span> - Sans <span class="math inline">\(j\)</span> : <span class="math inline">\(x_{-j}=(x_{(1)},\ldots,x_{(j-1)},z_{(j)},z_{(j+1)},\ldots,z_{(p)})\)</span> - Calculer la contribution marginale : <span class="math inline">\(\phi_j^{m}=\hat{f}(x_{+j})-\hat{f}(x_{-j})\)</span> - Calculez la valeur de Shapley comme moyenne : <span class="math inline">\(\phi_j(x)=\frac{1}{M}\sum_{m=1}^M\phi_j^{m}\)</span></p>
<p>Tout d’abord, sélectionnez une instance d’intérêt <span class="math inline">\(x\)</span>, une fonctionnalité <span class="math inline">\(j\)</span> et le nombre d’itérations <span class="math inline">\(M\)</span>. Pour chaque itération, une instance aléatoire <span class="math inline">\(z\)</span> est sélectionnée à partir des données et un ordre aléatoire des fonctionnalités est généré. Deux nouvelles instances sont créées en combinant les valeurs de l’instance d’intérêt <span class="math inline">\(x\)</span> et de l’échantillon <span class="math inline">\(z\)</span>. L’exemple <span class="math inline">\(x_{+j}\)</span> est l’instance qui nous intéresse, mais toutes les valeurs dans l’ordre après la caractéristique <span class="math inline">\(j\)</span> sont remplacées par les valeurs de caractéristiques de l’échantillon z. L’exemple <span class="math inline">\(x_{-j}\)</span> est le même que <span class="math inline">\(x_{+j}\)</span>, mais en plus la fonctionnalité <span class="math inline">\(j\)</span> est remplacée par la valeur de la fonctionnalité <span class="math inline">\(j\)</span> de l’échantillon <span class="math inline">\(z\)</span>. La différence entre la prédiction et la boîte noire est calculée :</p>
<p><span class="math display">\[\phi_j^{m}=\hat{f}(x^m_{+j})-\hat{f}(x^m_{-j})\]</span></p>
<p>Toutes ces différences sont moyennées et donnent :</p>
<p><span class="math display">\[\phi_j(x)=\frac{1}{M}\sum_{m=1}^M\phi_j^{m}\]</span></p>
<p>La moyenne pondère implicitement les échantillons selon la distribution de probabilité de X.</p>
<p>La procédure doit être répétée pour chacune des caractéristiques afin d’obtenir toutes les valeurs de Shapley.</p>
</section>
</section>
<section id="avantages" class="level3">
<h3 class="anchored" data-anchor-id="avantages">9.5.4 - Avantages</h3>
<p>La différence entre la prédiction et la prédiction moyenne est <strong>équitablement répartie</strong> entre les valeurs de caractéristiques de l’instance – la propriété Efficacité des valeurs de Shapley. Cette propriété distingue la valeur Shapley des autres méthodes telles que <a href="../09-local_model_agnostic_methods/09.2-lime.html">LIME</a> . LIME ne garantit pas que la prédiction soit équitablement répartie entre les fonctionnalités. La valeur de Shapley pourrait être la seule méthode permettant de fournir une explication complète. Dans les situations où la loi exige l’explicabilité – comme le « droit à des explications » de l’UE – la valeur Shapley pourrait être la seule méthode juridiquement conforme, car elle repose sur une théorie solide et répartit équitablement les effets. Je ne suis pas avocat, cela reflète donc uniquement mon intuition concernant les exigences.</p>
<p>La valeur de Shapley permet <strong>des explications contrastées</strong>. Au lieu de comparer une prédiction à la prédiction moyenne de l’ensemble de données, vous pouvez la comparer à un sous-ensemble ou même à un seul point de données. Cette contrastivité est également quelque chose que les modèles locaux comme LIME ne possèdent pas.</p>
<p>La valeur de Shapley est la seule méthode d’explication dotée d’une <strong>théorie solide</strong>. Les axiomes – efficacité, symétrie, muette, additivité – donnent à l’explication une base raisonnable. Des méthodes telles que LIME supposent un comportement linéaire du modèle d’apprentissage automatique localement, mais il n’existe aucune théorie expliquant pourquoi cela devrait fonctionner.</p>
<p>Il est époustouflant d’<strong>expliquer une prédiction comme un jeu</strong> joué par les valeurs des caractéristiques.</p>
</section>
<section id="inconvénients" class="level3">
<h3 class="anchored" data-anchor-id="inconvénients">9.5.5 - Inconvénients</h3>
<p>La valeur de Shapley nécessite <strong>beaucoup de temps de calcul</strong>. Dans <span class="math inline">\(99,9%\)</span> des problèmes du monde réel, seule la solution approximative est réalisable. Un calcul exact de la valeur de Shapley est coûteux en termes de calcul car il existe 2 k coalitions possibles de valeurs de caractéristiques et « l’absence » d’une caractéristique doit être simulée en tirant des instances aléatoires, ce qui augmente la variance pour l’estimation des valeurs de Shapley. Le nombre exponentiel des coalitions est traité en échantillonnant les coalitions et en limitant le nombre d’itérations M. Diminuer M réduit le temps de calcul, mais augmente la variance de la valeur de Shapley. Il n’existe pas de bonne règle empirique concernant le nombre d’itérations M. M doit être suffisamment grand pour estimer avec précision les valeurs de Shapley, mais suffisamment petit pour terminer le calcul dans un temps raisonnable. Il devrait être possible de choisir M en fonction des limites de Chernoff, mais je n’ai vu aucun article sur ce faisant pour les valeurs de Shapley pour les prédictions d’apprentissage automatique.</p>
<p>La valeur de Shapley <strong>peut être mal interprétée</strong>. La valeur Shapley d’une valeur de fonctionnalité n’est pas la différence de la valeur prédite après la suppression de la fonctionnalité de la formation du modèle. L’interprétation de la valeur de Shapley est la suivante : étant donné l’ensemble actuel de valeurs de caractéristiques, la contribution d’une valeur de caractéristique à la différence entre la prédiction réelle et la prédiction moyenne est la valeur de Shapley estimée.</p>
<p>La valeur Shapley n’est pas la bonne méthode d’explication si vous recherchez des explications clairsemées (explications contenant peu de fonctionnalités). Les explications créées avec la méthode des valeurs de Shapley <strong>utilisent toujours toutes les fonctionnalités</strong>. Les humains préfèrent les explications sélectives, telles que celles produites par LIME. LIME pourrait être le meilleur choix pour les explications auxquelles les profanes doivent faire face. Une autre solution est <a href="https://github.com/shap/shap">SHAP</a> introduite par Lundberg et Lee (2016)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, qui est basée sur la valeur de Shapley, mais peut également fournir des explications avec peu de fonctionnalités.</p>
<p>La valeur Shapley renvoie une valeur simple par fonctionnalité, mais <strong>aucun modèle de prédiction</strong> comme LIME. Cela signifie qu’il ne peut pas être utilisé pour faire des déclarations sur les changements de prédiction en fonction des changements dans les entrées, telles que : “Si je devais gagner 300 € de plus par an, ma cote de crédit augmenterait de 5 points.”</p>
<p>Un autre inconvénient est que <strong>vous devez accéder aux données</strong> si vous souhaitez calculer la valeur Shapley pour une nouvelle instance de données. Il ne suffit pas d’accéder à la fonction de prédiction, car vous avez besoin que les données remplacent des parties de l’instance d’intérêt par des valeurs provenant d’instances de données tirées au hasard. Cela ne peut être évité que si vous pouvez créer des instances de données qui ressemblent à des instances de données réelles mais ne sont pas de véritables instances à partir des données d’entraînement.</p>
<p>Comme beaucoup d’autres méthodes d’interprétation basées sur la permutation, la méthode des valeurs de Shapley souffre de l’<strong>inclusion d’instances de données irréalistes</strong> lorsque les caractéristiques sont corrélées. Pour simuler l’absence d’une valeur de fonctionnalité dans une coalition, nous marginalisons la fonctionnalité. Ceci est réalisé en échantillonnant les valeurs de la distribution marginale de l’entité. C’est très bien tant que les fonctionnalités sont indépendantes. Lorsque les fonctionnalités sont dépendantes, nous pouvons alors échantillonner des valeurs de fonctionnalités qui n’ont pas de sens pour cette instance. Mais nous les utiliserions pour calculer la valeur Shapley de la fonctionnalité. Une solution pourrait consister à permuter les caractéristiques corrélées ensemble et à obtenir une valeur Shapley mutuelle pour elles. Une autre adaptation est l’échantillonnage conditionnel : les fonctionnalités sont échantillonnées en fonction des fonctionnalités qui font déjà partie de l’équipe. Alors que l’échantillonnage conditionnel résout le problème des points de données irréalistes, un nouveau problème est introduit : les valeurs résultantes ne sont plus les valeurs de Shapley dans notre jeu, car elles violent l’axiome de symétrie, comme l’ont découvert Sundararajan et al.&nbsp;(2019)<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> et discuté plus en détail par Janzing et al.&nbsp;(2020)<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
</section>
<section id="logiciels-et-alternatives" class="level3">
<h3 class="anchored" data-anchor-id="logiciels-et-alternatives">9.5.6 - Logiciels et alternatives</h3>
<p>Les valeurs Shapley sont implémentées dans les packages <code>iml</code> et <a href="https://github.com/bgreenwell/fastshap">fastshap</a> pour R. Dans Julia, vous pouvez utiliser <a href="https://gitlab.com/ExpandingMan/Shapley.jl">Shapley.jl</a>.</p>
<p>SHAP, une méthode alternative d’estimation des valeurs de Shapley, est présentée dans le <a href="../09-local_model_agnostic_methods/09.6-shap.html">chapitre suivant</a>.</p>
<p>Une autre approche est appelée breakDown, qui est implémentée dans le <code>breakDown</code> package R<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. BreakDown affiche également les contributions de chaque fonctionnalité à la prédiction, mais les calcule étape par étape. Réutilisons l’analogie du jeu : nous commençons avec une équipe vide, ajoutons la valeur de fonctionnalité qui contribuerait le plus à la prédiction et itérons jusqu’à ce que toutes les valeurs de fonctionnalité soient ajoutées. La contribution de chaque valeur de fonctionnalité dépend des valeurs de fonctionnalité respectives qui sont déjà dans « l’équipe », ce qui est le gros inconvénient de la méthode breakDown. Elle est plus rapide que la méthode des valeurs de Shapley et pour les modèles sans interactions, les résultats sont les mêmes.</p>
<!-- REFERENCES -->


</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Retour au sommet</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notes de bas de page</h2>

<ol>
<li id="fn1"><p>Shapley, Lloyd S. “A value for n-person games.” Contributions to the Theory of Games 2.28 (1953): 307-317.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Štrumbelj, Erik, and Igor Kononenko. “Explaining prediction models and individual predictions with feature contributions.” Knowledge and information systems 41.3 (2014): 647-665.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Lundberg, Scott M., and Su-In Lee. “A unified approach to interpreting model predictions.” Advances in Neural Information Processing Systems (2017).<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Sundararajan, Mukund, and Amir Najmi. “The many Shapley values for model explanation.” arXiv preprint arXiv:1908.08474 (2019).<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Janzing, Dominik, Lenon Minorics, and Patrick Blöbaum. “Feature relevance quantification in explainable AI: A causal problem.” International Conference on Artificial Intelligence and Statistics. PMLR (2020).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Staniak, Mateusz, and Przemyslaw Biecek. “Explanations of model predictions with live and breakDown packages.” arXiv preprint arXiv:1804.01955 (2018).<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../09-local_model_agnostic_methods/09.4-anchors.html" class="pagination-link  aria-label=" 9.4="" -="" règles="" de="" portée="" (ancres)"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">9.4 - Règles de portée (ancres)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../09-local_model_agnostic_methods/09.6-shap.html" class="pagination-link" aria-label="9.6 - SHAP (SHapley Additive exPlanations)">
        <span class="nav-page-text">9.6 - SHAP (SHapley Additive exPlanations)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>