<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Apprentissage automatique interprétable</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../11-future/index.html" rel="next">
<link href="../10-neuralnet/10.4-adversarial-examples.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer",
    "search-label": "Recherche"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../10-neuralnet/index.html">10 - Interprétation d’un réseau de neurone</a></li><li class="breadcrumb-item"><a href="../10-neuralnet/10.5-influential-instances.html">10.5 - Instances Influentes</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Apprentissage automatique interprétable</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../00-summary/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Résumé</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../01-preface/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - Préface de l’auteur</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../02-introduction/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.1-short_stories.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.1 - Quelques histoires</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.2-ml_definitions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.2 - Qu’est-ce que l’apprentissage automatique ?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../02-introduction/02.3-terminology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2.3 - Terminologie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../03-interpretability/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - Interprétabilité</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.1-importance_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.1 - Importance de l’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.2-taxonomy_of_interpretability_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.2 - Taxonomie des Méthodes d’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.3-scope_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.3 - Portée de l’Interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.4-evaluation_of_interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.4 - Evaluation de l’interprétabilité</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.5-properties_of_explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.5 - Propriétés des Explications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../03-interpretability/03.6-human_friendly_explanations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3.6 - Explications conviviales pour l’être humain</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../04-datasets/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - Jeux de données</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.1-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.1 - Location de vélo (Régression)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.2-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.2 - Commentaires indésirables sur YouTube (Classification de Texte)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../04-datasets/04.3-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4.3 - Facteurs de Risque du Cancer du Col de l’Uterus (Classification)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../05-interpretable_models/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - Modèles interprétables</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.1-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.1 - Régéression linéaire</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.2-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.2 - Régéression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.3-glm-gam-more.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.3 - GLM, GAM et plus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.4-decision-tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.4 - Arbre de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.5-decision-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.5 - Règles de décision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.6-rulefit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.6 - Ajustement des règles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../05-interpretable_models/05.7-other-interpretable-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5.7 - Autres modèles interprétables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../06-model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 - Méthodes indépendantes du modèle</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../07-example/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 - Explications basées sur des exemples</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../08-global_model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 - Méthodes globales indépendantes du modèle</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.1-pdp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.1 - Diagramme de dépendance partielle (PDP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.2-ale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.2 - Graphique des effets locaux accumulés (ALE)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.3-feature-interaction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.3 - Interactions avec les fonctionnalités</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.4-functional-decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.4 - Functional Decomposition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.5-permutation-feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.5 - Décomposition fonctionnelle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.6-global-surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.6 - Substitut global</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../08-global_model_agnostic_methods/08.7-prototype-criticisms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8.7 - Prototypes et critiques</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../09-local_model_agnostic_methods/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 - Méthodes locales indépendantes du modèle</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.1-ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.1 - Attente Conditionnelle Individuelle (<em>Individual Conditional Expectation - ICE</em>)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.2-lime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.2 - Substitut local (LIME)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.3-counterfactual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.3 - Explications contrefactuelles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.4-anchors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.4 - Règles de portée (ancres)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.5-shapley.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.5 - Valeurs de Shapley</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../09-local_model_agnostic_methods/09.6-shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9.6 - SHAP (SHapley Additive exPlanations)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../10-neuralnet/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10 - Interprétation d'un réseau de neurone</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.1-learned-features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.1 - Caractéristiques apprises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.2-pixel-attribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.2 - Attribution de pixel</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.3-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.3 - Détecter les concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.4-adversarial-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10.4 - Exemples adverses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../10-neuralnet/10.5-influential-instances.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">10.5 - Instances Influentes</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../11-future/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 - Un Regard dans une boule de cristal</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../11-future/11.1-future-ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11.1 - L’avenir de l’apprentissage automatique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../11-future/11.2-future-interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11.2 - L’avenir de l’interprétabilité</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../12-contribute/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 - Contribuer à ce livre</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../13-citation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 - Citer ce livre</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../14-translations/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14 - Traductions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../15-acknowledgements/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15 - Remerciements</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="4">
    <h2 id="toc-title">Dans cette page</h2>
   
  <ul>
  <li><a href="#instances-influentes" id="toc-instances-influentes" class="nav-link active" data-scroll-target="#instances-influentes">10.5 - Instances Influentes</a>
  <ul>
  <li><a href="#diagnostics-par-suppression" id="toc-diagnostics-par-suppression" class="nav-link" data-scroll-target="#diagnostics-par-suppression">10.5.1 - Diagnostics par suppression</a></li>
  <li><a href="#fonction-dinfluence" id="toc-fonction-dinfluence" class="nav-link" data-scroll-target="#fonction-dinfluence">10.5.2 - Fonction d’influence</a></li>
  <li><a href="#avantages-didentifier-les-instances-influentes" id="toc-avantages-didentifier-les-instances-influentes" class="nav-link" data-scroll-target="#avantages-didentifier-les-instances-influentes">10.5.3 - Avantages d’identifier les instances influentes</a></li>
  <li><a href="#inconvénients-didentifier-les-instances-influentes" id="toc-inconvénients-didentifier-les-instances-influentes" class="nav-link" data-scroll-target="#inconvénients-didentifier-les-instances-influentes">10.5.4 - Inconvénients d’identifier les instances influentes</a></li>
  <li><a href="#logiciel-et-alternatives" id="toc-logiciel-et-alternatives" class="nav-link" data-scroll-target="#logiciel-et-alternatives">10.5.5 - Logiciel et alternatives</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../10-neuralnet/index.html">10 - Interprétation d’un réseau de neurone</a></li><li class="breadcrumb-item"><a href="../10-neuralnet/10.5-influential-instances.html">10.5 - Instances Influentes</a></li></ol></nav>
<div class="quarto-title">
</div>



<div class="quarto-title-meta">

    
  
    <div>
    <div class="quarto-title-meta-heading">Modifié</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">10 mai 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="instances-influentes" class="level2">
<h2 class="anchored" data-anchor-id="instances-influentes">10.5 - Instances Influentes</h2>
<p>Les modèles d’apprentissage automatique sont finalement le produit des données d’entraînement et la suppression d’une des instances d’entraînement peut affecter le modèle résultant. Nous qualifierons une instance d’entraînement d’“influente” lorsque sa suppression des données d’entraînement change considérablement les paramètres ou les prédictions du modèle. En identifiant les instances d’entraînement influentes, nous pouvons “déboguer” les modèles d’apprentissage automatique et mieux expliquer leurs comportements et prédictions.</p>
<p>Ce chapitre vous montre deux approches pour identifier les instances influentes, à savoir les diagnostics de suppression et les fonctions d’influence. Les deux approches sont basées sur la statistique robuste, qui fournit des méthodes statistiques moins affectées par les valeurs aberrantes ou les violations des hypothèses du modèle. La statistique robuste fournit également des méthodes pour mesurer la robustesse des estimations à partir des données (comme une estimation moyenne ou les poids d’un modèle de prédiction).</p>
<p>Imaginez que vous voulez estimer le revenu moyen des habitants de votre ville et demandez à dix personnes choisies au hasard dans la rue combien elles gagnent. Outre le fait que votre échantillon est probablement vraiment mauvais, à quel point votre estimation du revenu moyen peut-elle être influencée par une seule personne ? Pour répondre à cette question, vous pouvez recalculer la valeur moyenne en omettant des réponses individuelles ou dériver mathématiquement via des “fonctions d’influence” comment la valeur moyenne peut être influencée. Avec l’approche de suppression, nous recalculons la valeur moyenne dix fois, en omettant une des déclarations de revenus à chaque fois, et mesurons à quel point l’estimation moyenne change. Un grand changement signifie qu’une instance était très influente. La deuxième approche surpondère l’une des personnes par un poids infinitésimalement petit, ce qui correspond au calcul de la première dérivée d’une statistique ou d’un modèle. Cette approche est également connue sous le nom d’“approche infinitésimale” ou “fonction d’influence”. La réponse est, en passant, que votre estimation moyenne peut être très fortement influencée par une seule réponse, puisque la moyenne évolue linéairement avec les valeurs individuelles. Un choix plus robuste est la médiane (la valeur pour laquelle la moitié des gens gagnent plus et l’autre moitié moins), car même si la personne avec le revenu le plus élevé de votre échantillon gagnait dix fois plus, la médiane résultante ne changerait pas.</p>
<p>Les diagnostics de suppression et les fonctions d’influence peuvent également être appliqués aux paramètres ou prédictions des modèles d’apprentissage automatique pour mieux comprendre leur comportement ou pour expliquer des prédictions individuelles. Avant de regarder ces deux approches pour trouver des instances influentes, nous examinerons la différence entre une valeur aberrante et une instance influente.</p>
<p><strong>Valeur extrême</strong></p>
<p>Une valeur aberrante est une instance qui est éloignée des autres instances dans l’ensemble de données. “Éloignée” signifie que la distance, par exemple la distance euclidienne, à toutes les autres instances est très grande. Dans un ensemble de données de nouveau-nés, un nouveau-né pesant 6 kg serait considéré comme une valeur aberrante. Dans un ensemble de données de comptes bancaires comprenant principalement des comptes courants, un compte de prêt dédié (solde négatif important, peu de transactions) serait considéré comme une valeur aberrante. La figure suivante montre une valeur aberrante pour une distribution unidimensionnelle.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/outlier.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Feature x follows a Gaussian distribution with an outlier at x=8.</figcaption>
</figure>
</div>
<p>Les valeurs extrêmes peuvent représenter des points intéressants (p.&nbsp;ex. <a href="../08-global_model_agnostic_methods/08.7-prototype-criticisms.html">critiques</a>). Quand une valeur extrême influence le modèle, elle peut être une instance influente.</p>
<p><strong>Instance influente</strong></p>
<p>Une instance influente est une instance de données dont la suppression a un fort effet sur le modèle entraîné. Plus les paramètres ou les prédictions du modèle changent lorsque le modèle est réentraîné avec une instance particulière retirée des données d’entraînement, plus cette instance est influente. Le fait qu’une instance soit influente pour un modèle entraîné dépend également de sa valeur pour la cible y. La figure suivante montre une instance influente pour un modèle de régression linéaire.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/influential_instance.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>A linear model with one feature. Trained once on the full data and once without the influential instance. Removing the influential instance changes the fitted slope (weight/coefficient) drastically.</figcaption>
</figure>
</div>
<p><strong>Pourquoi les instances influentes aident-elles à comprendre le modèle ?</strong></p>
<p>L’idée clé derrière les instances influentes pour l’interprétabilité est de remonter aux origines des paramètres et des prédictions du modèle : les données d’entraînement. Un apprenant, c’est-à-dire l’algorithme qui génère le modèle d’apprentissage automatique, est une fonction qui prend des données d’entraînement constituées de caractéristiques X et de la cible y et génère un modèle d’apprentissage automatique. Par exemple, l’apprenant d’un arbre de décision est un algorithme qui sélectionne les caractéristiques de division et les valeurs auxquelles diviser. Un apprenant pour un réseau neuronal utilise la rétropropagation pour trouver les meilleurs poids.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images/learner.png" class="img-fluid figure-img" data-align="center" width="200"></p>
<figcaption>A learner learns a model from training data (features plus target). The model makes predictions for new data.</figcaption>
</figure>
</div>
<p>Nous nous demandons comment les paramètres du modèle ou les prédictions changeraient si nous retirions des instances des données d’entraînement dans le processus de formation. Cela contraste avec d’autres approches d’interprétabilité qui analysent comment la prédiction change lorsque nous manipulons les caractéristiques des instances à prédire, telles que les <a href="../08-global_model_agnostic_methods/08.1-pdp.html">graphiques de dépendance partielle</a> ou l’<a href="../08-global_model_agnostic_methods/08.5-permutation-feature-importance.html">importance des caractéristiques</a>. Avec les instances influentes, nous ne traitons pas le modèle comme fixe, mais comme une fonction des données d’entraînement. Les instances influentes nous aident à répondre à des questions sur le comportement global du modèle et sur des prédictions individuelles. Quelles étaient les instances les plus influentes pour les paramètres du modèle ou les prédictions dans l’ensemble ? Quelles étaient les instances les plus influentes pour une prédiction particulière ? Les instances influentes nous indiquent pour quelles instances le modèle pourrait avoir des problèmes, quelles instances d’entraînement devraient être vérifiées pour des erreurs et donnent une impression de la robustesse du modèle. Nous pourrions ne pas faire confiance à un modèle si une seule instance a une forte influence sur les prédictions et les paramètres du modèle. Au moins, cela nous inciterait à enquêter davantage.</p>
<p>Comment pouvons-nous trouver des instances influentes ? Nous avons deux façons de mesurer l’influence : Notre première option est de supprimer l’instance des données d’entraînement, de réentraîner le modèle sur l’ensemble de données d’entraînement réduit et d’observer la différence dans les paramètres du modèle ou les prédictions (soit individuellement, soit sur l’ensemble complet des données). La deuxième option est de surpondérer une instance de données en approximant les changements de paramètres basés sur les gradients des paramètres du modèle. L’approche de suppression est plus facile à comprendre et motive l’approche de surpondération, donc nous commençons par la première.</p>
<section id="diagnostics-par-suppression" class="level3">
<h3 class="anchored" data-anchor-id="diagnostics-par-suppression">10.5.1 - Diagnostics par suppression</h3>
<p>Les statisticiens ont déjà beaucoup recherché dans le domaine des instances influentes, en particulier pour les modèles de régression linéaire (généralisée). Lorsque vous recherchez “observations influentes”, les premiers résultats de recherche concernent des mesures telles que DFBETA et la distance de Cook. <strong>DFBETA</strong> mesure l’effet de la suppression d’une instance sur les paramètres du modèle. <strong>La distance de Cook</strong> (Cook, 1977<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) mesure l’effet de la suppression d’une instance sur les prédictions du modèle. Pour les deux mesures, nous devons réentraîner le modèle à plusieurs reprises, en omettant des instances individuelles à chaque fois. Les paramètres ou prédictions du modèle avec toutes les instances sont comparés avec les paramètres ou prédictions du modèle avec l’une des instances supprimée des données d’entraînement.</p>
<p>DFBETA est défini comme suit :</p>
<p><span class="math display">\[DFBETA_{i}=\beta-\beta^{(-i)}\]</span></p>
<p>où <span class="math inline">\(\beta\)</span> est le vecteur de poids lorsque le modèle est entraîné sur toutes les instances de données, et <span class="math inline">\(\beta^{(-i)}\)</span> le vecteur de poids lorsque le modèle est entraîné sans l’instance <span class="math inline">\(i\)</span>. Assez intuitif je dirais. DFBETA ne fonctionne que pour les modèles avec des paramètres de poids, tels que la régression logistique ou les réseaux neuronaux, mais pas pour des modèles tels que les arbres de décision, les ensembles d’arbres, certaines machines à vecteurs de support, etc.</p>
<p>La distance de Cook a été inventée pour les modèles de régression linéaire et des approximations pour les modèles de régression linéaire généralisée existent. La distance de Cook pour une instance d’entraînement est définie comme la somme (mise à l’échelle) des différences au carré dans le résultat prédit lorsque la <span class="math inline">\(i^{ième}\)</span>instance est retirée de l’entraînement du modèle.</p>
<p><span class="math display">\[D_i=\frac{\sum_{j=1}^n(\hat{y}_j-\hat{y}_{j}^{(-i)})^2}{p\cdot{}MSE}\]</span></p>
<p>où le numérateur est la différence au carré entre la prédiction du modèle avec et sans la <span class="math inline">\(i^{ième}\)</span> instance, sommée sur l’ensemble de données. Le dénominateur est le nombre de caractéristiques <span class="math inline">\(p\)</span> fois l’erreur quadratique moyenne (<em>MSE : Mean Square Error</em>). Le dénominateur est le même pour toutes les instances, peu importe quelle instance <span class="math inline">\(i\)</span> est retirée. La distance de Cook nous indique à quel point le résultat prédit d’un modèle linéaire change lorsque nous retirons la <span class="math inline">\(i^{ième}\)</span> instance de l’entraînement.</p>
<p>Pouvons-nous utiliser la distance de Cook et DFBETA pour tout modèle d’apprentissage automatique ? DFBETA nécessite des paramètres de modèle, donc cette mesure fonctionne uniquement pour les modèles paramétrés. La distance de Cook ne nécessite aucun paramètre de modèle. Fait intéressant, la distance de Cook n’est généralement pas vue en dehors du contexte des modèles linéaires et des modèles linéaires généralisés, mais l’idée de prendre la différence entre les prédictions du modèle avant et après la suppression d’une instance particulière est très générale. Un problème avec la définition de la distance de Cook est la MSE, qui n’est pas significative pour tous les types de modèles de prédiction (par exemple, la classification).</p>
<p>La mesure d’influence la plus simple pour l’effet sur les prédictions du modèle peut s’écrire comme suit :</p>
<p><span class="math display">\[\text{Influence}^{(-i)}=\frac{1}{n}\sum_{j=1}^{n}\left|\hat{y}_j-\hat{y}_{j}^{(-i)}\right|\]</span></p>
<p>Cette expression est essentiellement le numérateur de la distance de Cook, avec la différence que la différence absolue est ajoutée au lieu des différences au carré. C’était un choix que j’ai fait, car il a du sens pour les exemples plus tard. La forme générale des mesures de diagnostic de suppression consiste à choisir une mesure (comme le résultat prédit) et à calculer la différence de la mesure pour le modèle entraîné sur toutes les instances et lorsque l’instance est supprimée.</p>
<p>Nous pouvons facilement décomposer l’influence pour expliquer pour la prédiction de l’instance <span class="math inline">\(j\)</span> quelle était l’influence de l’instance d’entraînement <span class="math inline">\(i^{ième}\)</span> :</p>
<p><span class="math display">\[\text{Influence}_{j}^{(-i)}=\left|\hat{y}_j-\hat{y}_{j}^{(-i)}\right|\]</span></p>
<p>Cela fonctionnerait également pour la différence dans les paramètres du modèle ou la différence dans la perte. Dans l’exemple suivant, nous utiliserons ces mesures d’influence simples.</p>
<p><strong>Exemple de diagnostic par suppression</strong></p>
<p>Dans l’exemple suivant, nous entraînons une machine à vecteurs de support pour prédire le <a href="../04-datasets/04.3-datasets.html">cancer du col de l’utérus</a> en fonction des facteurs de risque et mesurons quelles instances d’entraînement ont été les plus influentes dans l’ensemble et pour une prédiction particulière. Étant donné que la prédiction du cancer est un problème de classification, nous mesurons l’influence comme la différence de probabilité prédite pour le cancer. Une instance est influente si la probabilité prédite augmente ou diminue fortement en moyenne dans l’ensemble de données lorsque l’instance est retirée de l’entraînement du modèle. La mesure de l’influence pour toutes les <code>r nrow(cervical)</code> instances d’entraînement nécessite d’entraîner le modèle une fois sur toutes les données et de le réentraîner <code>r nrow(cervical)</code> fois (= taille des données d’entraînement) avec une des instances retirée à chaque fois.</p>
<p>L’instance la plus influente a une mesure d’influence d’environ <code>r sprintf("%.2f", abs(df[1,"influence"]))</code>. Une influence de <code>r sprintf('%.2f', abs(df[1,"influence"]))</code> signifie que si nous retirons l’instance <code>r df$id[1]</code>, la probabilité prédite change en moyenne de <code>r sprintf('%.0f', 100 * df[1,"influence"])</code> points de pourcentage. C’est assez considérable étant donné que la probabilité prédite moyenne pour le cancer est de <code>r sprintf('%.1f', 100 *mean(predicted.orig))</code>%. La valeur moyenne des mesures d’influence sur toutes les suppressions possibles est de <code>r sprintf('%.1f', 100 * mean(abs(df$influence)))</code> points de pourcentage. Maintenant, nous savons quelles sont les instances de données les plus influentes pour le modèle. Cela est déjà utile à savoir pour déboguer les données. Y a-t-il une instance problématique ? Y a-t-il des erreurs de mesure ? Les instances influentes sont les premières à vérifier pour les erreurs, car chaque erreur en elles influence fortement les prédictions du modèle.</p>
<p>En dehors du débogage du modèle, pouvons-nous apprendre quelque chose pour mieux comprendre le modèle ? Imprimer simplement les dix instances les plus influentes n’est pas très utile, car il s’agit juste d’une table d’instances avec de nombreuses caractéristiques. Toutes les méthodes qui retournent des instances en sortie n’ont de sens que si nous avons un bon moyen de les représenter. Mais nous pouvons mieux comprendre quel type d’instances est influent lorsque nous nous demandons : Qu’est-ce qui distingue une instance influente d’une instance non influente ? Nous pouvons transformer cette question en un problème de régression et modéliser l’influence d’une instance en fonction de ses valeurs de caractéristiques. Nous sommes libres de choisir n’importe quel modèle du chapitre sur les <a href="../05-interpretable_models/">Modèles d’Apprentissage Automatique Interprétables</a>. Pour cet exemple, j’ai choisi un arbre de décision (figure suivante) qui montre que les données des femmes de 35 ans et plus étaient les plus influentes pour la machine à vecteurs de support. Parmi toutes les femmes de l’ensemble de données <code>r sum(cervical$Age &gt;= 35)</code> sur <code>r nrow(cervical)</code> étaient âgées de plus de 35 ans. Dans le chapitre sur les <a href="../08-global_model_agnostic_methods/08.1-pdp.html">Graphiques de Dépendance Partielle</a>, nous avons vu qu’après 40 ans, il y a une augmentation marquée de la probabilité prédite de cancer et l’<a href="../08-global_model_agnostic_methods/08.5-permutation-feature-importance.html">Importance des Caractéristiques</a> a également détecté l’âge comme l’une des caractéristiques les plus importantes. L’analyse de l’influence nous dit que le modèle devient de plus en plus instable lors de la prédiction du cancer pour les âges plus élevés. Cela en soi est une information précieuse. Cela signifie que les erreurs dans ces instances peuvent avoir un fort effet sur le modèle.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/deletion_diagnostics_1.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>A decision tree that models the relationship between the influence of the instances and their features. The maximum depth of the tree is set to 2.</figcaption>
</figure>
</div>
<p>Cette première analyse d’influence a révélé l’instance la plus influente <em>dans l’ensemble</em>. Maintenant, nous sélectionnons l’une des instances, à savoir l’instance <code>r i</code>, pour laquelle nous voulons expliquer la prédiction en trouvant les instances de données d’entraînement les plus influentes. C’est comme une question contrefactuelle : Comment la prédiction pour l’instance <code>r i</code> changerait-elle si nous omettions l’instance i du processus d’entraînement ? Nous répétons cette suppression pour toutes les instances. Ensuite, nous sélectionnons les instances d’entraînement qui entraînent le plus grand changement dans la prédiction de l’instance <code>r i</code> lorsqu’elles sont omises de l’entraînement et les utilisons pour expliquer la prédiction du modèle pour cette instance. J’ai choisi d’expliquer la prédiction pour l’instance <code>r i</code> car c’est l’instance avec la probabilité prédite la plus élevée de cancer (<code>r sprintf('%.2f', 100 * predicted.orig[i])</code>%), que je pensais être un cas intéressant à analyser plus en profondeur. Nous pourrions retourner, disons, les 10 instances les plus influentes pour prédire l’instance <code>r i</code> imprimées sous forme de tableau. Pas très utile, car nous ne pourrions pas voir grand-chose. Encore une fois, il est plus logique de découvrir ce qui distingue les instances influentes des instances non influentes en analysant leurs caractéristiques. Nous utilisons un arbre de décision formé pour prédire l’influence étant donné les caractéristiques, mais en réalité, nous le détournons seulement pour trouver une structure et non pour prédire réellement quelque chose. L’arbre de décision suivant montre quel type d’instances d’entraînement était le plus influent pour prédire la <code>r i</code> instance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/deletion_diagnostics_2.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Decision tree that explains which instances were most influential for predicting the 7-th instance. Data from women who smoked for 18.5 years or longer had a large influence on the prediction of the 7-th instance, with an average change in absolute prediction by 11.7 percentage points of cancer probability.</figcaption>
</figure>
</div>
<p>Les instances de données de femmes qui ont fumé ou fument depuis 18,5 ans ou plus ont une forte influence sur la prédiction de l’instance <code>r i</code>. La femme derrière l’instance <code>r i</code> a fumé pendant <code>r cervical$Smokes..years.[i]</code> ans. Dans les données, <code>r sum(cervical$Smokes..years &gt;= 18.5)</code> femmes (<code>r sprintf('%.2f', 100 * mean(cervical$Smokes..years &gt;= 18.5))</code>%) ont fumé pendant 18,5 ans ou plus. Toute erreur commise dans la collecte du nombre d’années de tabagisme de l’une de ces femmes aura un impact énorme sur le résultat prédit pour l’instance <code>r i</code>.</p>
<p>Le changement le plus extrême dans la prédiction se produit lorsque nous supprimons l’instance numéro <code>r worst.case.index</code>. La patiente aurait fumé pendant <code>r cervical$Smokes..years.[worst.case.index]</code> ans, ce qui correspond aux résultats de l’arbre de décision. La probabilité prédite pour l’instance <code>r i</code> passe de <code>r sprintf('%.2f', 100 * predicted.orig[i])</code>% à <code>r sprintf('%.2f', 100 * (predicted.orig[i]  - cervical.200$influence[worst.case.index]))</code>% si nous retirons l’instance <code>r worst.case.index</code> !</p>
<p>Si nous examinons de plus près les caractéristiques de l’instance la plus influente, nous pouvons voir un autre problème possible. Les données indiquent que la femme a 28 ans et fume depuis 22 ans. Soit c’est un cas vraiment extrême et elle a vraiment commencé à fumer à 6 ans, soit c’est une erreur de données. Je penche pour cette dernière hypothèse. C’est certainement une situation dans laquelle nous devons remettre en question l’exactitude des données.</p>
<p>Ces exemples ont montré à quel point il est utile d’identifier les instances influentes pour déboguer des modèles. Un problème avec l’approche proposée est que le modèle doit être réentraîné pour chaque instance d’entraînement. Le réentraînement complet peut être assez lent, car si vous avez des milliers d’instances d’entraînement, vous devrez réentraîner votre modèle des milliers de fois. En supposant que le modèle prend un jour pour s’entraîner et que vous avez 1000 instances d’entraînement, alors le calcul des instances influentes – sans parallélisation – prendra presque 3 ans. Personne n’a le temps pour cela. Dans le reste de ce chapitre, je vous montrerai une méthode qui ne nécessite pas de réentraîner le modèle.</p>
</section>
<section id="fonction-dinfluence" class="level3">
<h3 class="anchored" data-anchor-id="fonction-dinfluence">10.5.2 - Fonction d’influence</h3>
<p><em>Vous</em> : Je veux connaître l’influence qu’une instance d’entraînement a sur une prédiction particulière.<br>
<em>Recherche</em> : Vous pouvez supprimer l’instance d’entraînement, réentraîner le modèle et mesurer la différence dans la prédiction.<br>
<em>Vous</em> : Génial ! Mais avez-vous une méthode pour moi qui fonctionne sans réentraînement ? Cela prend tellement de temps.<br>
<em>Recherche</em> : Avez-vous un modèle avec une fonction de perte qui est deux fois différentiable par rapport à ses paramètres ?<br>
<em>Vous</em> : J’ai entraîné un réseau neuronal avec la perte logistique. Donc oui.<br>
<em>Recherche</em> : Alors vous pouvez approximer l’influence de l’instance sur les paramètres du modèle et sur la prédiction avec des <strong>fonctions d’influence</strong>. La fonction d’influence est une mesure de la force avec laquelle les paramètres du modèle ou les prédictions dépendent d’une instance d’entraînement. Au lieu de supprimer l’instance, la méthode surpondère l’instance dans la perte par un très petit pas. Cette méthode implique d’approximer la perte autour des paramètres actuels du modèle en utilisant le gradient et la matrice hessienne. La surpondération de la perte est similaire à la suppression de l’instance.<br>
<em>Vous</em> : Super, c’est ce que je recherche !</p>
<p>Koh et Liang (2017)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> ont suggéré d’utiliser les fonctions d’influence, une méthode de statistique robuste, pour mesurer comment une instance influence les paramètres du modèle ou les prédictions. Comme avec les diagnostics de suppression, les fonctions d’influence retracent les paramètres du modèle et les prédictions jusqu’à l’instance d’entraînement responsable. Cependant, au lieu de supprimer des instances d’entraînement, la méthode approxime à quel point le modèle change lorsque l’instance est surpondérée dans le risque empirique (somme de la perte sur les données d’entraînement).</p>
<p>La méthode des fonctions d’influence nécessite un accès au gradient de la perte par rapport aux paramètres du modèle, ce qui ne fonctionne que pour un sous-ensemble de modèles d’apprentissage automatique. La régression logistique, les réseaux neuronaux et les machines à vecteurs de support se qualifient, mais les méthodes basées sur des arbres comme les forêts aléatoires ne le font pas. Les fonctions d’influence aident à comprendre le comportement du modèle, à déboguer le modèle et à détecter des erreurs dans l’ensemble de données.</p>
<p>La section suivante explique l’intuition et les mathématiques derrière les fonctions d’influence.</p>
<p><strong>Mathématiques derrière les fonctions d’influence</strong></p>
<p>L’idée clé derrière les fonctions d’influence est de surpondérer la perte d’une instance d’entraînement par un petit pas infinitésimal <span class="math inline">\(\epsilon\)</span>, ce qui entraîne de nouveaux paramètres du modèle :</p>
<p><span class="math display">\[\hat{\theta}_{\epsilon,z}=\arg\min_{\theta{}\in\Theta}(1-\epsilon)\frac{1}{n}\sum_{i=1}^n{}L(z_i,\theta)+\epsilon{}L(z,\theta)\]</span></p>
<p>où <span class="math inline">\(\theta\)</span> est le vecteur de paramètres du modèle et <span class="math inline">\(\hat{\theta}_{\epsilon,z}\)</span> est le vecteur de paramètres après la surpondération de <span class="math inline">\(z\)</span> par un très petit nombre <span class="math inline">\(\epsilon\)</span>. <span class="math inline">\(L\)</span> est la fonction de perte avec laquelle le modèle a été entraîné, <span class="math inline">\(z_i\)</span> est les données d’entraînement et <span class="math inline">\(z\)</span> est l’instance d’entraînement que nous voulons surpondérer pour simuler sa suppression. L’intuition derrière cette formule est : À quel point la perte changera-t-elle si nous surpondérons une instance particulière <span class="math inline">\(z_i\)</span> des données d’entraînement d’un peu (<span class="math inline">\(\epsilon\)</span>) et sous-pondérons les autres instances de données en conséquence ? À quoi ressemblerait le vecteur de paramètres pour optimiser cette nouvelle perte combinée ? La fonction d’influence des paramètres, c’est-à-dire l’influence de la surpondération de l’instance d’entraînement <span class="math inline">\(z\)</span> sur les paramètres, peut être calculée comme suit.</p>
<p><span class="math display">\[I_{\text{up,params}}(z)=\left.\frac{d{}\hat{\theta}_{\epsilon,z}}{d\epsilon}\right|_{\epsilon=0}=-H_{\hat{\theta}}^{-1}\nabla_{\theta}L(z,\hat{\theta})\]</span></p>
<p>La dernière expression <span class="math inline">\(\nabla_{\theta}L(z,\hat{\theta})\)</span> est le gradient de la perte par rapport aux paramètres pour l’instance d’entraînement surpondérée. Le gradient est le taux de changement de la perte de l’instance d’entraînement. Il nous indique de combien la perte change lorsque nous changeons les paramètres du modèle <span class="math inline">\(\hat{\theta}\)</span> d’un peu. Une entrée positive dans le vecteur de gradient signifie qu’une petite augmentation du paramètre du modèle correspondant augmente la perte, une entrée négative signifie que l’augmentation du paramètre réduit la perte. La première partie <span class="math inline">\(H^{-1}_{\hat{\theta}}\)</span> est la matrice hessienne inverse (deuxième dérivée de la perte par rapport aux paramètres du modèle). La matrice hessienne est le taux de changement du gradient, ou exprimée en termes de perte, c’est le taux de changement du taux de changement de la perte. Elle peut être estimée en utilisant :</p>
<p><span class="math display">\[H_{\theta}=\frac{1}{n}\sum_{i=1}^n\nabla^2_{\hat{\theta}}L(z_i,\hat{\theta})\]</span></p>
<p>Plus informellement : La matrice hessienne enregistre la courbure de la perte à un certain point. La hessienne est une matrice et non juste un vecteur, car elle décrit la courbure de la perte et cette courbure dépend de la direction dans laquelle nous regardons. Le calcul réel de la matrice hessienne est chronophage si vous avez de nombreux paramètres. Koh et Liang ont suggéré quelques astuces pour la calculer efficacement, ce qui va au-delà du cadre de ce chapitre. Mettre à jour les paramètres du modèle, comme décrit par la formule ci-dessus, est équivalent à prendre une seule étape de Newton après avoir formé une expansion quadratique autour des paramètres estimés du modèle.</p>
<p>Quelle intuition se cache derrière cette formule de fonction d’influence ? La formule vient de la formation d’une expansion quadratique autour des paramètres <span class="math inline">\(\hat{\theta}\)</span>. Cela signifie que nous ne savons pas réellement, ou il est trop complexe de calculer comment exactement la perte de l’instance z changera lorsqu’elle est supprimée/surpondérée. Nous approximons localement la fonction en utilisant des informations sur la pente (i.e gradient) et la courbure (i.e matrice hessienne) à la configuration actuelle des paramètres du modèle. Avec cette approximation de la perte, nous pouvons calculer à quoi ressembleraient approximativement les nouveaux paramètres si nous surpondérions l’instance z :</p>
<p><span class="math display">\[\hat{\theta}_{-z}\approx\hat{\theta}-\frac{1}{n}I_{\text{up,params}}(z)\]</span></p>
<p>Le vecteur de paramètres approximatif est essentiellement le paramètre original moins le gradient de la perte de <span class="math inline">\(z\)</span> (car nous voulons diminuer la perte) ajusté par la courbure (i.e multiplié par la matrice hessienne inverse) et ajusté par <span class="math inline">\(1/n\)</span>, car c’est le poids d’une seule instance d’entraînement.</p>
<p>La figure suivante montre comment fonctionne la surpondération. L’axe des <span class="math inline">\(x\)</span> montre la valeur du paramètre <span class="math inline">\(\theta\)</span> et l’axe des <span class="math inline">\(y\)</span> la valeur correspondante de la perte avec l’instance <span class="math inline">\(z\)</span> surpondérée. Le paramètre du modèle est unidimensionnel à des fins de démonstration, mais en réalité, il est généralement de haute dimension. Nous ne nous déplaçons que de <span class="math inline">\(1/n\)</span> dans la direction de l’amélioration de la perte pour l’instance <span class="math inline">\(z\)</span>. Nous ne savons pas comment la perte changerait réellement lorsque nous supprimons <span class="math inline">\(z\)</span>, mais avec la première et la deuxième dérivée de la perte, nous créons cette approximation quadratique autour de notre paramètre de modèle actuel et prétendons que c’est ainsi que la perte réelle se comporterait.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../_static/images2/math_behind_influence_functions.png" class="img-fluid figure-img" data-align="center"></p>
<figcaption>Updating the model parameter (x-axis) by forming a quadratic expansion of the loss around the current model parameter, and moving 1/n into the direction in which the loss with upweighted instance z (y-axis) improves most. This upweighting of instance z in the loss approximates the parameter changes if we delete z and train the model on the reduced data.</figcaption>
</figure>
</div>
<p>Nous n’avons pas réellement besoin de calculer les nouveaux paramètres, mais nous pouvons utiliser la fonction d’influence comme mesure de l’influence de <span class="math inline">\(z\)</span> sur les paramètres.</p>
<p>Comment les <em>prédictions</em> changent-elles lorsque nous surpondérons l’instance d’entraînement <span class="math inline">\(z\)</span> ? Nous pouvons soit calculer les nouveaux paramètres, puis faire des prédictions en utilisant le modèle nouvellement paramétré, soit nous pouvons également calculer directement l’influence de l’instance <span class="math inline">\(z\)</span> sur les prédictions, car nous pouvons calculer l’influence en utilisant la règle de chaîne :</p>
<p><span class="math display">\[\begin{align*}I_{up,loss}(z,z_{test})&amp;=\left.\frac{d{}L(z_{test},\hat{\theta}_{\epsilon,z})}{d\epsilon}\right|_{\epsilon=0}\\&amp;=\left.\nabla_{\theta}L(z_{test},\hat{\theta})^T\frac{d\hat{\theta}_{\epsilon,z}}{d\epsilon}\right|_{\epsilon=0}\\&amp;=-\nabla_{\theta}L(z_{test},\hat{\theta})^T{}H^{-1}_{\theta}\nabla_{\theta}L(z,\hat{\theta})\end{align*}\]</span></p>
<p>La première ligne de cette équation signifie que nous mesurons l’influence d’une instance d’entraînement sur une certaine prédiction <span class="math inline">\(z_{test}\)</span> comme un changement de perte de l’instance de test lorsque nous surpondérons l’instance <span class="math inline">\(z\)</span> et obtenons de nouveaux paramètres <span class="math inline">\(\hat{\theta}_{\epsilon,z}\)</span>. Pour la deuxième ligne de l’équation, nous avons appliqué la règle de chaîne des dérivées et obtenons la dérivée de la perte de l’instance de test par rapport aux paramètres multipliée par l’influence de <span class="math inline">\(z\)</span> sur les paramètres. Dans la troisième ligne, nous remplaçons l’expression par la fonction d’influence pour les paramètres. Le premier terme de la troisième ligne <span class="math inline">\(\nabla_{\theta}L(z_{test},\hat{\theta})^T{}\)</span> est le gradient de l’instance de test par rapport aux paramètres du modèle.</p>
<p>Avoir une formule est formidable et la manière scientifique et précise de montrer les choses. Mais je pense qu’il est très important de comprendre l’intuition derrière la formule. La formule pour <span class="math inline">\(I_{\text{up,loss}}\)</span> indique que la fonction d’influence de l’instance d’entraînement <span class="math inline">\(z\)</span> sur la prédiction d’une instance <span class="math inline">\(z_{test}\)</span> est “à quel point l’instance réagit à un changement des paramètres du modèle” multipliée par “à quel point les paramètres changent lorsque nous surpondérons l’instance <span class="math inline">\(z\)</span>”. Une autre façon de lire la formule : L’influence est proportionnelle à la taille des gradients pour la perte d’entraînement et la perte de test. Plus le gradient de la perte d’entraînement est élevé, plus son influence sur les paramètres et plus l’influence sur la prédiction de test est élevée. Plus le gradient de la prédiction de test est élevé, plus l’instance de test est influençable. L’ensemble du construct peut également être vu comme une mesure de la similarité (telle qu’apprise par le modèle) entre l’instance d’entraînement et l’instance de test.</p>
<p>C’est tout pour la théorie et l’intuition. La section suivante explique comment les fonctions d’influence peuvent être appliquées.</p>
<p><strong>Application des Fonctions d’Influence</strong></p>
<p>Les fonctions d’influence ont de nombreuses applications, dont certaines ont déjà été présentées dans ce chapitre.</p>
<p><strong>Comprendre le comportement du modèle</strong></p>
<p>Différents modèles d’apprentissage automatique ont différentes manières de faire des prédictions. Même si deux modèles ont la même performance, la manière dont ils font des prédictions à partir des caractéristiques peut être très différente et donc échouer dans différents scénarios. Comprendre les faiblesses particulières d’un modèle en identifiant des instances influentes aide à former un “modèle mental” du comportement du modèle d’apprentissage automatique dans votre esprit.</p>
<p><strong>Gérer les inadéquations de domaine / Déboguer les erreurs du modèle</strong></p>
<p>La gestion de l’inadéquation de domaine est étroitement liée à une meilleure compréhension du comportement du modèle. L’inadéquation de domaine signifie que la distribution des données d’entraînement et de test est différente, ce qui peut amener le modèle à mal fonctionner sur les données de test. Les fonctions d’influence peuvent identifier des instances d’entraînement qui ont causé l’erreur. Supposons que vous avez formé un modèle de prédiction pour le résultat de patients ayant subi une chirurgie. Tous ces patients viennent du même hôpital. Maintenant, vous utilisez le modèle dans un autre hôpital et constatez qu’il ne fonctionne pas bien pour de nombreux patients. Bien sûr, vous supposez que les deux hôpitaux ont des patients différents, et si vous regardez leurs données, vous pouvez voir qu’ils diffèrent dans de nombreuses caractéristiques. Mais quelles sont les caractéristiques ou les instances qui ont “cassé” le modèle ? Ici aussi, les instances influentes sont un bon moyen de répondre à cette question. Vous prenez l’un des nouveaux patients, pour lequel le modèle a fait une fausse prédiction, trouvez et analysez les instances les plus influentes. Par exemple, cela pourrait montrer que le deuxième hôpital a en moyenne des patients plus âgés et les instances les plus influentes des données d’entraînement sont les quelques patients plus âgés du premier hôpital et le modèle manquait simplement de données pour apprendre à bien prédire ce sous-groupe. La conclusion serait que le modèle doit être entraîné sur plus de patients plus âgés pour bien fonctionner dans le deuxième hôpital.</p>
<p><strong>Corriger les données d’entraînement</strong></p>
<p>Si vous avez une limite sur le nombre d’instances d’entraînement que vous pouvez vérifier pour leur exactitude, comment faire une sélection efficace ? La meilleure façon est de sélectionner les instances les plus influentes, car – par définition – elles ont le plus d’influence sur le modèle. Même si vous aviez une instance avec des valeurs manifestement incorrectes, si l’instance n’est pas influente et que vous avez besoin des données uniquement pour le modèle de prédiction, il est préférable de vérifier les instances influentes. Par exemple, vous entraînez un modèle pour prédire si un patient doit rester à l’hôpital ou être libéré prématurément. Vous voulez vraiment vous assurer que le modèle est robuste et fait des prédictions correctes, car une libération erronée d’un patient peut avoir de mauvaises conséquences. Les dossiers des patients peuvent être très désordonnés, donc vous n’avez pas une confiance parfaite dans la qualité des données. Mais vérifier les informations des patients et les corriger peut prendre beaucoup de temps, car une fois que vous avez signalé quels patients vous devez vérifier, l’hôpital doit réellement envoyer quelqu’un pour examiner de plus près les dossiers des patients sélectionnés, qui pourraient être manuscrits et se trouver dans une archive. Vérifier les données d’un patient pourrait prendre une heure ou plus. Compte tenu de ces coûts, il est logique de vérifier seulement quelques instances de données importantes. La meilleure façon est de sélectionner des patients qui ont eu une forte influence sur le modèle de prédiction. Koh et Liang (2017) ont montré que ce type de sélection fonctionne beaucoup mieux qu’une sélection aléatoire ou la sélection de ceux avec la perte la plus élevée ou une classification incorrecte.</p>
</section>
<section id="avantages-didentifier-les-instances-influentes" class="level3">
<h3 class="anchored" data-anchor-id="avantages-didentifier-les-instances-influentes">10.5.3 - Avantages d’identifier les instances influentes</h3>
<p>Les approches des diagnostics de suppression et des fonctions d’influence sont très différentes des approches principalement basées sur la perturbation des caractéristiques présentées dans le <a href="../06-model_agnostic_methods/">chapitre Modèle-Agnostique</a>. Examiner les instances influentes met en évidence le rôle des données d’entraînement dans le processus d’apprentissage. Cela fait des fonctions d’influence et des diagnostics de suppression <strong>l’un des meilleurs outils de débogage pour les modèles d’apprentissage automatique</strong>. Parmi les techniques présentées dans ce livre, ce sont les seules qui aident directement à identifier les instances qui devraient être vérifiées pour des erreurs.</p>
<p><strong>Les diagnostics de suppression sont agnostiques au modèle</strong>, ce qui signifie que l’approche peut être appliquée à n’importe quel modèle. De même, les fonctions d’influence basées sur les dérivées peuvent être appliquées à une large classe de modèles.</p>
<p>Nous pouvons utiliser ces méthodes pour <strong>comparer différents modèles d’apprentissage automatique</strong> et mieux comprendre leurs comportements différents, allant au-delà de la comparaison de la seule performance prédictive.</p>
<p>Nous n’avons pas parlé de ce sujet dans ce chapitre, mais <strong>les fonctions d’influence via des dérivées peuvent également être utilisées pour créer des données d’entraînement adverses</strong>. Ce sont des instances qui sont manipulées de telle manière que le modèle ne peut pas prédire correctement certaines instances de test lorsque le modèle est entraîné sur ces instances manipulées. La différence avec les méthodes du <a href="../10-neuralnet/10.4-adversarial-examples.html">chapitre Exemples Adverses</a> est que l’attaque a lieu pendant le temps d’entraînement, également connue sous le nom d’attaques de contamination. Si cela vous intéresse, lisez l’article de Koh et Liang (2017).</p>
<p>Pour les diagnostics de suppression et les fonctions d’influence, nous avons considéré la différence dans la prédiction et pour la fonction d’influence l’augmentation de la perte. Mais, en réalité, <strong>l’approche est généralisable</strong> à toute question de la forme : “Que se passe-t-il pour … lorsque nous supprimons ou surpondérons l’instance <span class="math inline">\(z\)</span> ?”, où vous pouvez remplir “…” avec toute fonction de votre modèle de votre choix. Vous pouvez analyser à quel point une instance d’entraînement influence la perte globale du modèle. Vous pouvez analyser à quel point une instance d’entraînement influence l’importance des caractéristiques. Vous pouvez analyser à quel point une instance d’entraînement influence la caractéristique sélectionnée pour la première division lors de l’entraînement d’un <a href="../05-interpretable_models/05.4-decision-tree.html">arbre de décision</a>.</p>
<p>Il est également possible d’<strong>identifier des groupes d’instances influentes</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
</section>
<section id="inconvénients-didentifier-les-instances-influentes" class="level3">
<h3 class="anchored" data-anchor-id="inconvénients-didentifier-les-instances-influentes">10.5.4 - Inconvénients d’identifier les instances influentes</h3>
<p>Les diagnostics de suppression sont très <strong>coûteux à calculer</strong> car ils nécessitent un réentraînement. Mais l’histoire a montré que les ressources informatiques augmentent constamment. Un calcul qui, il y a 20 ans, était impensable en termes de ressources peut facilement être effectué avec votre smartphone. Vous pouvez entraîner des modèles avec des milliers d’instances d’entraînement et des centaines de paramètres sur un ordinateur portable en quelques secondes ou minutes. Il n’est donc pas difficile d’imaginer que les diagnostics de suppression fonctionneront sans problème même avec de grands réseaux neuronaux dans 10 ans.</p>
<p><strong>Les fonctions d’influence sont une bonne alternative aux diagnostics de suppression, mais uniquement pour les modèles avec une fonction de perte différentiable au 2ème ordre par rapport à ses paramètres</strong>, tels que les réseaux neuronaux. Elles ne fonctionnent pas pour les méthodes basées sur les arbres comme les forêts aléatoires, les arbres boostés ou les arbres de décision. Même si vous avez des modèles avec des paramètres et une fonction de perte, la perte peut ne pas être différentiable. Mais pour le dernier problème, il y a une astuce : Utilisez une perte différentiable comme substitut pour calculer l’influence lorsque, par exemple, le modèle sous-jacent utilise la perte Hinge au lieu d’une perte différentiable. La perte est remplacée par une version lissée de la perte problématique pour les fonctions d’influence, mais le modèle peut toujours être entraîné avec la perte non lisse.</p>
<p><strong>Les fonctions d’influence ne sont qu’approximatives</strong>, car l’approche forme une expansion quadratique autour des paramètres. L’approximation peut être erronée et l’influence d’une instance peut en réalité être plus élevée ou plus faible lorsqu’elle est supprimée. Koh et Liang (2017) ont montré pour certains exemples que l’influence calculée par la fonction d’influence était proche de la mesure d’influence obtenue lorsque le modèle était réellement réentraîné après la suppression de l’instance. Mais il n’y a aucune garantie que l’approximation sera toujours aussi proche.</p>
<p>Il n’y a <strong>pas de seuil clair de la mesure d’influence à partir duquel nous appelons une instance influente ou non influente</strong>. Il est utile de classer les instances par influence, mais il serait formidable de disposer des moyens non seulement de trier les instances, mais aussi de distinguer réellement entre influentes et non influentes. Par exemple, si vous identifiez les 10 instances d’entraînement les plus influentes pour une instance de test, certaines d’entre elles peuvent ne pas être influentes car, par exemple, seules les 3 premières étaient réellement influentes.</p>
</section>
<section id="logiciel-et-alternatives" class="level3">
<h3 class="anchored" data-anchor-id="logiciel-et-alternatives">10.5.5 - Logiciel et alternatives</h3>
<p>Les diagnostics de suppression sont très simples à mettre en œuvre. Consultez <a href="https://github.com/christophM/interpretable-ml-book/blob/master/manuscript/06.5-example-based-influence-fct.Rmd">le code</a> que j’ai écrit pour les exemples de ce chapitre.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Note du traducteur">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note du traducteur
</div>
</div>
<div class="callout-body-container callout-body">
<p>Accès au code de cette page dans Github -&gt; python + FR + allégée ?</p>
</div>
</div>
<p>Pour les modèles linéaires et les modèles linéaires généralisés, de nombreuses mesures d’influence comme la distance de Cook sont implémentées dans R dans le package <code>stats</code>.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Note du traducteur">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note du traducteur
</div>
</div>
<div class="callout-body-container callout-body">
<p>Equivalent(s) Python ?</p>
</div>
</div>
<p>Koh et Liang ont publié le code Python pour les fonctions d’influence de leur article <a href="https://github.com/kohpangwei/influence-release">dans un dépôt</a>. C’est génial ! Malheureusement, il s’agit “seulement” du code de l’article et non d’un module Python maintenu et documenté. Le code est axé sur la bibliothèque Tensorflow, donc vous ne pouvez pas l’utiliser directement pour des modèles boîte noire utilisant d’autres frameworks, comme sci-kit learn.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Note du traducteur">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note du traducteur
</div>
</div>
<div class="callout-body-container callout-body">
<p>Et depuis ?</p>
</div>
</div>
<!-- REFERENCES -->


</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Retour au sommet</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Notes de bas de page</h2>

<ol>
<li id="fn1"><p>Cook, R. Dennis. “Detection of influential observation in linear regression.” Technometrics 19.1 (1977): 15-18.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Koh, Pang Wei, and Percy Liang. “Understanding black-box predictions via influence functions.” arXiv preprint arXiv:1703.04730 (2017).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Koh, Pang Wei, Kai-Siang Ang, Hubert HK Teo, and Percy Liang. “On the accuracy of influence functions for measuring group effects.” arXiv preprint arXiv:1905.13289 (2019).<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../10-neuralnet/10.4-adversarial-examples.html" class="pagination-link  aria-label=" 10.4="" -="" exemples="" adverses"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">10.4 - Exemples adverses</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../11-future/index.html" class="pagination-link" aria-label="11 - Un Regard dans une boule de cristal">
        <span class="nav-page-text">11 - Un Regard dans une boule de cristal</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>